"""Constants and utility functions for NSP

Date -- 24.05.2023
Author -- Martin Kostelnik
"""

import typing

from sklearn import metrics
from transformers import BertTokenizerFast


CZERT_PATH = r"UWB-AIR/Czert-B-base-cased"

JOKER = chr(65533) # Special character used in PERO OCR as a JOKER

# These characters can be generated by PERO OCR but are unknown to Huggingface tokenizer
# We either replace them with similliar character or with JOKER
UNKNOWN_CHARS = {
        "—": "-",
        "ϵ": JOKER,
        "℥": JOKER,
        "‘": JOKER,
        "’": JOKER,
        "`": JOKER,
        "“": '"',
        "☞": JOKER,
        "☜": JOKER,
        "˛": ".",
        "⁂": JOKER,
        "ꝛ": JOKER,
        "Ꙃ": "z",
        "Ꙁ": "z",
        "Ꙋ": JOKER,
        "Ѡ": JOKER,
        "Ꙗ": JOKER,
        "Ѥ": JOKER,
        "Ѭ": JOKER,
        "Ѩ": JOKER,
        "Ѯ": JOKER,
        "Ѱ": JOKER,
        "Ѵ": "v",
        "Ҁ": "c",
        "ꙃ": "z",
        "ꙁ": "z",
        "ꙋ": JOKER,
        "ѡ": "w",
        "ꙗ": JOKER,
        "ѥ": JOKER,
        "ѭ": JOKER,
        "ѩ": JOKER,
        "ѯ": JOKER,
        "ѱ": JOKER,
        "ѵ": "v",
        "ҁ": "c",
        "Ӕ": JOKER,
        "ӕ": JOKER,
        "Ϲ": "c",
        "ϲ": "c",
        "ϳ": "j",
        "ϝ": "f",
        "Ⱥ": "a",
        "ⱥ": "a",
        "Ɇ": "e",
        "ɇ": "e",
        "ᵱ": "p",
        "ꝓ": "p",
        "ꝑ": "p",
        "ꝙ": "q",
        "ꝗ": "q",
        "ꝟ": "v",
}

# These characters cause problems in Huggingface tokenizer and text parsing
# They are removed from OCR texts
# Note that this changes the length of the text
TRUNCATED_CHARS = ["ͤ", "̄", "̾", "̃", "̊"]


def remove_accents(text: str) -> str:
    """Remove accents from text.

        Parameters
        ----------
        text : str
            Text from which accents will be removed. Certain special characters
            are replaced by similliar standard characters or replaced with PERO OCR JOKER.

        Returns
        -------
        text_ : str
            Text with removed accents
    """

    # Replace unknown chars so huggingface tokenizer does not generate [UNK] tokens
    for to_replace, replace_with in UNKNOWN_CHARS.items():
        text_ = text.replace(to_replace, replace_with)

    # Remove special accent characters that get discarded by the tokenizer
    for to_remove in TRUNCATED_CHARS:
        text_ = text_.replace(to_remove, "")

    return text_


def load_data(path: str):
    data = []

    with open(path, "r") as f:
        for line in f:
            sen1, sen2, label = line.split("\t")

            data.append((sen1.strip(), sen2.strip(), int(label)))

    return data


def evaluate(ground_truth: list, predictions: list, full: bool = False) -> None:
    """Compare predictions with ground truth and print metrics.

        Parameters
        ----------
        ground_truth : list
            Ground truth values
        predictions : list
            Model predictions
    """

    print(metrics.classification_report(ground_truth, predictions, target_names=["IsNextStc", "IsNotNextStc"], digits=4))
    print(f"         AUC     {metrics.roc_auc_score(ground_truth, predictions):.4f}\n")

    fpr, tpr, threshold = metrics.roc_curve(ground_truth, predictions)
    
    if full:
        plt.clf()
        plt.title(f"ROC")
        plt.plot(fpr, tpr, "b")
        plt.plot([0, 1], [0, 1],"r--")
        plt.xlim([0, 1])
        plt.ylim([0, 1])
        plt.ylabel("True Positive Rate")
        plt.xlabel("False Positive Rate")
        plt.savefig("ROC.pdf")

    # TODO: Add confusion matrix


def n_params(model, trainable_only: bool = True) -> int:
    if trainable_only:
        return sum(p.numel() for p in model.parameters() if p.requires_grad)
    else:
        return sum(p.numel() for p in model.parameters())


def build_tokenizer():
    tokenizer = BertTokenizerFast.from_pretrained(CZERT_PATH)
    tokenizer.add_special_tokens({"additional_special_tokens": [JOKER]})

    return tokenizer
